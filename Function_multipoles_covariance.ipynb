{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23659082-ab02-43b0-9da0-200285e5260e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_data(min_k, max_k, pk_data, covariance_data, n_poles): #Función para establecer las dimensiones de los datos en función de los límites de k\n",
    "    for i in range(len(pk_data[:,0:1])):\n",
    "        if pk_data[:,0:1][i]==min_k:\n",
    "            n = i\n",
    "        if pk_data[:,0:1][i]==max_k:\n",
    "            m = i\n",
    "    s = int(len(covariance_data[0])/n_poles)        \n",
    "    p_subfile = pk_data[:,1:2][n:m+1]\n",
    "    if n_poles==2:\n",
    "        p = np.vstack((p_subfile,pk_data[:,2:3][n:m+1]))\n",
    "    if n_poles ==3:\n",
    "        p_1 = np.vstack((p_subfile, pk_data[:,2:3][n:m+1]))\n",
    "        p = np.vstack((p_1, pk_data[:,3:][n:m+1]))\n",
    "    print('Dimensiones del vector de datos de multipolos: ', p.shape) #Creamos un vector con los datos de los 3 multipolos (p0,p2,p4)\n",
    "    if n_poles == 2:\n",
    "        mask1 = covariance_data[n:m+1, n:m+1]\n",
    "        mask2 = covariance_data[n:m+1, n+s:m+1+s]\n",
    "        mask4 = covariance_data[n+s:m+1+s, n:m+1]\n",
    "        mask5 = covariance_data[n+s:m+1+s, n+s:m+1+s]\n",
    "        mask7 = covariance_data[n+(2*s):m+1+(2*s), n:m+1]\n",
    "        mask8 = covariance_data[n+(2*s):m+1+(2*s), n+s:m+1+s]\n",
    "        h1 = np.hstack((mask1,mask2))\n",
    "        h3 = np.hstack((mask4, mask5))\n",
    "        h5 = np.hstack((mask7,mask8))\n",
    "        final1 = np.vstack((h1,h3))\n",
    "        final = np.vstack((final1, h5))\n",
    "        new_covariance = final\n",
    "    if n_poles ==3:\n",
    "        mask1 = covariance_data[n:m+1, n:m+1]\n",
    "        mask2 = covariance_data[n:m+1, n+s:m+1+s]\n",
    "        mask3 = covariance_data[n:m+1, n+(2*s):m+1+(2*s)]\n",
    "        mask4 = covariance_data[n+s:m+1+s, n:m+1]\n",
    "        mask5 = covariance_data[n+s:m+1+s, n+s:m+1+s]\n",
    "        mask6 = covariance_data[n+s:m+1+s, n+(2*s):m+1+(2*s)]\n",
    "        mask7 = covariance_data[n+(2*s):m+1+(2*s), n:m+1]\n",
    "        mask8 = covariance_data[n+(2*s):m+1+(2*s), n+s:m+1+s]\n",
    "        mask9 = covariance_data[n+(2*s):m+1+(2*s), n+(2*s):m+1+(2*s)]\n",
    "        h1 = np.hstack((mask1,mask2))\n",
    "        h2 = np.hstack((h1, mask3))\n",
    "        h3 = np.hstack((mask4, mask5))\n",
    "        h4 = np.hstack((h3, mask6))\n",
    "        h5 = np.hstack((mask7,mask8))\n",
    "        h6 = np.hstack((h5, mask9))\n",
    "        final1 = np.vstack((h2,h4))\n",
    "        final = np.vstack((final1, h6))\n",
    "        new_covariance = final\n",
    "    num_k = [min_k, max_k,(max_k - min_k)/(len(p)/n_poles)]    \n",
    "    print('Las dimensiones de la matriz de covarianza son: ', new_covariance.shape)#Creamos una matriz de covarianza nueva, eliminando los datos que exceden los límites de k\n",
    "    return p, new_covariance, np.array(num_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
